# Лямбда-исчисление

Лямбда-исчисление это анонимные функции превращённые в формальную систему. Синтаксис:

$$\begin{aligned}
{\color{red}expr} ::=\ &{\color{red}var} & &\text{(имя переменной)} \\
\mid\quad &λ\, {\color{red}var}\, .\ {\color{red}expr} & &\text{(абстракция)} \\
\mid\quad &{\color{red}expr}\ {\color{red}expr} & &\text{(применение)}
\end{aligned}$$

Имя переменной может содержать более одного символа. Кроме того, мы различаем строчные буквы от заглавных: $ab$ и $aB$ это два разных имени.

Применение левоассоциативно: $\color{red} f\ v_1\ v_2$ означает $({\color{red} f\ v_1})\ {\color{red}v_2}$. Кроме того, абстракция захватывает всё, что находится справа её.

Мы будем использовать следующее сокращение:
- ${λ\color{red} v_1\, v_2}.\; \color{red}e$ означает $λ\textcolor{red}{v_1}.\;(λ\textcolor{red}{v_2}.\; \textcolor{red}{e})$.
- $λ{\color{red} v_1\,v_2\,v_3}.\; \textcolor{red}e$ означает $λ\textcolor{red}{v_1}.\;(λ\textcolor{red}{v_2}.\; (λ\textcolor{red}{v_3}.\;\textcolor{red}e))$.
- И так далее

Например, $λ x\, y.\; x$ это то же самое, что и $λx.\; λ y.\; x$.

Предназначение переменных — указывать места для подстановки. Однако, наличие имён у переменных порождает проблемы.

Например, что означает $λx.\; λx.\; x$?

Мы решим подобные неоднозначности довольно механическим способом. Для начала, пара определений:

- Вхождение переменной в выражение это переменная в конкретной позиции в выражении.

- Вхождение переменной при абстракции (например, ${\color{red}x}$ в $λ{\color{red}x}.\;{\color{red}e}$) называется *связывающим*.

Для удобства, мы считаем связывающие вхождения переменных не листом синтаксического дерева, а частью абстракции.

Каждое синтаксическое дерево можно рассматривать как набор путей от корня к листьям. Например, выражение $λf.\; (λx.\; x)\ (λy.\; f\ w)$ раскладывается на пути следующим образом:

- $λf.\;\bullet ⟶ λx.\;\bullet ⟶ x$
- $λf.\;\bullet ⟶ λy.\;\bullet ⟶ \bullet\ \bullet ⟶ f$
- $λf.\;\bullet ⟶ λy.\;\bullet ⟶ \bullet\ \bullet ⟶ w$

В каждом пути пронумеруем переменные следующим образом:

1. Двигаясь слева направо, нумеруем связывающие переменные в порядке их появления
2. Для переменной в конце пути, ищем ближайшую к ней связывающую переменную. Если находим, то помечаем лист той же цифрой, что и у связывающей переменной

Пронумеровав переменные в примере выше, получаем следующие пути:

- $λf^0.\;\bullet ⟶ λx^1.\;\bullet ⟶ x^1$
- $λf^0.\;\bullet ⟶ λy^1.\;\bullet ⟶ \bullet\ \bullet ⟶ f^0$
- $λf^0.\;\bullet ⟶ λy^1.\;\bullet ⟶ \bullet\ \bullet ⟶ w$

Они соответствуют выражению $λf^0.\; (λx^1.\; x^1)\ (λy^1.\; f^0\ w)$.

Нумерация устраняет неоднозначности, связанные с именами. Например, пронумеровав $λx.\; λx.\; x$, получаем $λx^0.\; λx^1.\; x^1$ — выражение, где переменная явным образом связана со внутренней абстракцией, а не внешней.

Кроме того, теперь мы можем классифицировать вхождения переменных в листах синтаксического дерева:

- Пронумерованные вхождения называются *связанными*
- Вхождения без номеров называются *свободными*

Связанные вхождения указывают места для подстановки значений, когда же свободные переменные можно рассматривать как внешние определения.

Можно заметить, что номера сами по себе однозначно указывают места подстановки. Заменив связанные вхождения на номера и удалив связывающие вхождения, получаем локально безымянное предствление.

Вот несколько выражений в локально безымянном предствлении:

$$\begin{aligned}
&λx.\;x &\qquad &λ.\; \underline 0 \\
&λx.\;λy.\;y & &λ.\; λ.\ \underline 1 \\
&(λx.\;λy.\; y\ x)\ z & &(λ.\;λ.\; \underline 1\ \underline 0)\ z
\end{aligned}$$

Выражения $\color{red}e_1$ и $\color{red}e_2$ называются альфа-эквивалентными (пишется $\textcolor{red}{e_1} \equiv_α \textcolor{red}{e_2}$), если их локально безымянные формы совпадает.

Альфа-эквивалентность выражает то, что смысл выражения не зависит от имён связанных переменных: например, $λx.\;x$ и $λt.\;t$ это по сути одно и то же выражение.

Далее, мы будем считать альфа-эквивалентные выражения одним и тем же выражением.

---

Если свободная переменная это внешнее определение, то можно подставить значение на её место.

$\textcolor{red}e[\textcolor{red}x := \textcolor{red}v]$ это выражение, где каждое свободное вхождение переменной $\textcolor{red}x$ заменено на выражение $\textcolor{red}v$.

Например, результатом $(λx.\; I\ I\ x)[I := λt.\; t]$ будет $λx.\; (λt.\;t)\ (λt.\;t)\ x$.

---

Но есть тонкость:

- $(λx.\; f\ x)[f := z]$ это $λx^0.\; z\ x^0$, где $z$ — свободная переменная
- Но если наивно подставить $f := z$ в $λz. f\ z$, то результатом будет $λz^0.\; z^0\ z^0$, где $z$ оказалась связана

Поэтому, подстановка должна давать новые имена связанным переменным, чьи имена совпадают с именами свободных переменных в подставляемом выражении.

И результатом $(λz.\; f\ z)[f := z]$ будет выражениие, где связанная переменная $z$ имеет другое имя — например, $λt.\; z\ t$.

---

С помощью подстановки можно сформулировать правила вычисления лямбда-выражений:

$$(λ\textcolor{red}x.\;\textcolor{red}e)\ \textcolor{red}v \longrightarrow {\textcolor{red}e}[{\textcolor{red}x := {\textcolor{red}v}}]$$

Применение правила это замена подвыражения (редекса), соответствующего левой части правила, выражением в правой части правила.


---

Мы пишем ${\color{red}e_1} ⟶ {\color{red}e_2}$, если применение бета-редукции к ${\color{red}e_1}$ даёт выражение ${\color{red}e_2}$.

Мы пишем ${\color{red}e_1} \xrightarrow{*} {\color{red}e_2}$, если применение конечного числа (включая нуль)
редукций к выражению ${\color{red}e_1}$ даёт выражение ${\color{red}e_2}$.

Правила вычисления не говорят, какой именно редекс заменяется, и потому одно и то же выражение можно вычислять по разному:

$$\begin{aligned}
(λx\,y.\; x)\ ((λx.\;x)\ z) &⟶ λy.\; ((λx.\;x)\ z) &⟶ λy.\;z \\
(λx\,y.\; x)\ ((λx.\;x)\ z) &⟶ (λx\,y.\; x)\ z &⟶ λy.\;z
\end{aligned}$$

---

Несмотря на то, что вычислять можно по разному, всегда есть возможность придти к одному и тому же результату.

**Теорема (Чёрч — Россер):** Пусть ${\color{red}e} \xrightarrow{*} {\color{red}a}$ и ${\color{red}e} \xrightarrow{*} {\color{red}b}$. Тогда существует такое выражение $\color{red}c$, что ${\color{red}a} \xrightarrow{*} {\color{red}с}$ и ${\color{red}b} \xrightarrow{*} {\color{red}c}$.

Это важнейшая теорема лямбда-исчисления. Но доказывать мы её не будем.

Утверждение теоремы можно изобразить диаграммой.

---

https://q.uiver.app/?q=WzAsNCxbMSwwLCJ7XFxjb2xvcntyZWR9ZX0iXSxbMCwxLCJ7XFxjb2xvcntyZWR9YX0iXSxbMiwxLCJ7XFxjb2xvcntyZWR9Yn0iXSxbMSwyLCJ7XFxjb2xvcntyZWR9YWJ9Il0sWzAsMSwiKiIsMl0sWzAsMiwiKiJdLFsyLDMsIioiLDJdLFsxLDMsIioiXV0=

---

Выражение $\color{red}a$ вычислительно равно выражению $\color{red}b$ (пишется ${\color{red}a} \equiv {\color{red}b}$), если существует такое выражение $\color{red}c$, что ${\color{red}a} \xrightarrow{*} {\color{red}c}$ и ${\color{red}b} \xrightarrow{*} {\color{red}c}$.

Вычислительное равенство удовлетворяет основным свойствам эквивалентности:

- ${\color{red}e} ≡ {\color{red}e}$
- Если ${\color{red}a} \equiv {\color{red}b}$, то ${\color{red}b} \equiv {\color{red}a}$
- Если ${\color{red}a} ≡ {\color{red}b}$ и ${\color{red}b} ≡ {\color{red}c}$, то ${\color{red}a} ≡ {\color{red}c}$

Первые два свойства следуют непосредственно из определения. Последнее же следует из теоремы Чёрча — Россера, что проще всего показать диаграммой.

---

https://q.uiver.app/?q=WzAsNixbMCwwLCJ7XFxjb2xvcntyZWR9YX0iXSxbMiwwLCJ7XFxjb2xvcntyZWR9Yn0iXSxbNCwwLCJ7XFxjb2xvcntyZWR9Y30iXSxbMSwxLCJ7XFxjb2xvcntyZWR9YWJ9Il0sWzMsMSwie1xcY29sb3J7cmVkfWJjfSJdLFsyLDIsIntcXGNvbG9ye3JlZH1hYmN9Il0sWzAsMywiKiJdLFsxLDMsIioiLDJdLFsxLDQsIioiXSxbMiw0LCIqIiwyXSxbMyw1LCIqIl0sWzQsNSwiKiIsMl1d


---

Выражение $\color{red}n$ находится в нормальной форме, если к нему невозможно применить правило вычисления.

Говорят, что $\color{red}n$ является нормальной формой выражения $\color{red}e$, если $\color{red}n$ находится в нормальной форме и  ${\color{red}e} \xrightarrow{*} {\color{red}n}$.

Из теоремы Чёрча — Россера следует, что у выражения может быть только одна нормальная форма. Кроме того, если два выражения имеют одну и ту же нормальную форму, то они вычислительно равны.

---

Не каждое выражение имеет нормальную форму:

$$\begin{aligned}
(λx.\;x\ x)\ (λx.\;x\ x) &⟶ (λx.\;x\ x)\ (λx.\;x\ x) &⟶ \dots \\
(λx.\;x\ x\ x)\ (λx.\;x\ x\ x) &⟶ (λx.\;x\ x\ x)\ (λx.\;x\ x\ x)\ (λx.\;x\ x\ x) &⟶ \dots
\end{aligned}$$

И даже если у выражения есть нормальная форма, не каждая стратегия вычисления к ней приводит:

$$\begin{aligned}
(λx\,y.\; y)\ ((λx.\;x\ x)\ (λx.\;x\ x)) &⟶ (λx\,y.\; y)\ ((λx.\;x\ x)\ (λx.\;x\ x)) &⟶ \dots \\
(λx\,y.\; y)\ ((λx.\;x\ x)\ (λx.\;x\ x)) &⟶ λy.\;y
\end{aligned}$$

Хотя теорема Чёрча — Россера гарантирует, что всегда есть способ достигнуть нормальной формы, она не заставляет ему следовать.

---

Мы ранее видели рекурсивные определения функции, и по аналогии можем ввести рекурсивные определения в лямбда-исчисление:

$$r := λx.\; {\color{red}e}\ r\ x$$

Однако, это не требуется, так как рекурсивные вычисления выразимы в лямбда исчислении без каких либо дополнительных расширений.

Чтобы понять, как, определим $r$ чуть иначе:

$$r := (λf.\;λx.\; {\color{red}e}\ f\ x)\ r$$

Чтобы выразить это определение в лямбда-исчислении, нужно найти такое выражение $r$, что

$$r \equiv (λf.\;λx.\; {\color{red}e}\ f\ x)\ r$$

---

Обобщаем задачу: ищем такое $Y$, что $Y\ f \equiv f\ (Y\ f)$. Чтобы его найти, вспомним выражение, что вычисляется в само себя:

$$(λx.\;x\ x)\ (λx.\;x\ x) ⟶ (λx.\;x\ x)\ (λx.\;x\ x)$$

Вставив в него $f$, получаем:

$$(λx.\;f\ (x\ x))\ (λx.\;f\ (x\ x)) ⟶ f\ ((λx.\;f\ x\ x)\ (λx.\;f\ x\ x))$$

Именно то, что и требовалось. Таким образом:

$$Y := λf.\;(λx.\;f\ (x\ x))\ (λx.\;f\ (x\ x))$$

Выражение $Y$ называется комбинатором неподвижной точки.
